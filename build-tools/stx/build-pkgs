#!/usr/bin/python3

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Copyright (C) 2021-2022 Wind River Systems,Inc

import argparse
import debrepack
import debsentry
import discovery
import dsc_depend
import dsccache
import logging
import os
import repo_manage
import requests
import shutil
import signal
import subprocess
import sys
import time
import utils
import yaml


BUILDER_URL = os.environ.get('BUILDER_URL')
REPOMGR_URL = os.environ.get('REPOMGR_URL')
BUILD_ROOT = os.environ.get('MY_BUILD_PKG_DIR')
STX_ROOT = os.environ.get('MY_REPO_ROOT_DIR')
PKGBUILDER_ROOT = "/localdisk/pkgbuilder"
USER = os.environ.get('MYUNAME')
PROJECT = os.environ.get('PROJECT')
# Different reasons can lead to package build failure
# Set maximum retry count for failed packages
MAX_PKG_BUILD_COUNT = 3

# TODO - Do we want a seperate repo for each layer? each build type?
REPO_BUILD = 'deb-local-build'
REPO_SOURCE = 'deb-local-source'

# Listed all stx source layers which contains 'debian_pkg_dirs'
STX_SOURCE_REPOS = [
    'SDO-rv-service',
    'ansible-playbooks',
    'audit-armada-app',
    'cert-manager-armada-app',
    'clients',
    'compile',
    'config',
    'config-files',
    'containers',
    'distributedcloud',
    'distributedcloud-client',
    'fault',
    'gui',
    'ha',
    'helm-charts',
    'integ',
    'kernel',
    'metal',
    'metrics-server-armada-app',
    'monitor-armada-app',
    'monitoring',
    'nfv',
    'nginx-ingress-controller-armada-app',
    'oidc-auth-armada-app',
    'openstack-armada-app',
    'platform-armada-app',
    'portieris-armada-app',
    'ptp-notification-armada-app',
    'rook-ceph',
    'snmp-armada-app',
    'stx-puppet',
    'update',
    'upstream',
    'utilities',
    'vault-armada-app',
]

STX_DEFAULT_DISTRO = discovery.STX_DEFAULT_DISTRO
STX_DEFAULT_BUILD_TYPE = discovery.STX_DEFAULT_BUILD_TYPE
STX_DEFAULT_BUILD_TYPE_LIST = discovery.STX_DEFAULT_BUILD_TYPE_LIST

ALL_DISTROS = discovery.get_all_distros()
ALL_LAYERS = discovery.get_all_layers(distro=STX_DEFAULT_DISTRO)
ALL_BUILD_TYPES = discovery.get_all_build_types(distro=STX_DEFAULT_DISTRO)

logger = logging.getLogger('debcontroller')
utils.set_logger(logger)


def get_pkg_dir_from_dsc(dscs, dsc_path):
    for pkg_dir, dsc in dscs.items():
        if dsc.strip() in dsc_path:
            return pkg_dir
    return None


def get_dsc_list_from_dict(dscs_dict):
    dsc_list = []
    for pkg_dir, dsc in dscs_dict.items():
        dsc_list.append(dsc)
    return dsc_list


def get_pkgname_ver_with_deb(deb_name):
    if not deb_name.endswith('.deb'):
        return None
    name_list = deb_name.split('_')
    if len(name_list) < 2:
        return None
    return name_list[0], name_list[1]


def req_chroots_action(action, extra_params):
    """
    Base function called by each require on chroot with Restful API
    Param:
      action: addchroot, loadchroot, savechroot
    """
    req_params = {}
    req_params['project'] = PROJECT
    req_params['user'] = USER

    if extra_params:
        req_params.update(extra_params)
    try:
        resp = requests.get(BUILDER_URL + action, data=req_params)
        resp.raise_for_status()
    except requests.RequestException as e:
        print(e)
    else:
        logger.debug(resp.text)
        if 'success' in resp.text:
            return 'success'
        if 'exists' in resp.text:
            return 'success'
        if 'creating' in resp.text:
            return 'creating'
    return 'fail'


def show_task_log(log_file, wait_time, success_str, exit_str):
    """
    Display the log file on the current console
    Param:
    wait_time: customer defines to wait before the log file can be read
    key_str: the separate string can be taken as flag to exit
    """
    status = 'fail'
    time.sleep(wait_time)
    logger.debug(' '.join(['Waiting for log file', log_file]))

    timeout = 8
    time_counter = 0
    while not os.path.exists(log_file):
        time.sleep(1)
        time_counter += 1
        if time_counter > timeout:
            break

    if os.path.exists(log_file):
        p = subprocess.Popen("tail -f " + log_file, stdout=subprocess.PIPE,
                             shell=True, universal_newlines=True, bufsize=0)
        while p.poll() is None:
            line = p.stdout.readline()
            line = line.strip()
            if line:
                print(line)
                if success_str and success_str in line:
                    status = 'success'
                    break
                if exit_str and exit_str in line:
                    logger.error(' '.join(['Task failed. For details please',
                                           'consult log', log_file]))
                    status = 'fail'
                    break
    return status


def pkgdirs_entry_handler(entry):
    if entry:
        return os.path.basename(entry)
    return []


def get_all_packages():
    """
    Scan all STX source layers to get all buildable packages
    Params: None
    Return:
        List of all STX buildable packages
    """
    pkgs = []
    projects_root = os.environ.get('MY_REPO')
    for root, dirs, files in os.walk(projects_root):
        if dirs:
            pass
        for r in files:
            if r == 'debian_pkg_dirs':
                pkgs_file = os.path.join(root, r)
                pkgs.extend(bc_safe_fetch(pkgs_file, pkgdirs_entry_handler))
    # Remove duplication
    return list(set(pkgs))


def get_package_jobs(pkg_dir, distro=STX_DEFAULT_DISTRO):
    '''
    Returns the number of parallel jobs of the package
    If the serial build is not enabled by the meta file,
    the default number of jobs is equal to the value of
    environment variable MAX_CPUS.
    '''
    jobs = os.environ.get('MAX_CPUS', 1)
    package = discovery.package_dir_to_package_name(pkg_dir, distro=distro)
    if pkg_dir:
        pkg_meta_yaml = os.path.join(pkg_dir, 'debian/meta_data.yaml')
        try:
            with open(pkg_meta_yaml) as f:
                yaml_doc = yaml.safe_load(f)
        except Exception as e:
            logger.error(str(e))
        else:
            # serial: true  [Disable parallel build]
            # No 'serial:' or 'serial: false' [Support parallel build]
            if yaml_doc.get('serial'):
                jobs = 1
    logger.debug('Requires the number of jobs %s for %s', jobs, package)
    return jobs


class BuildController():
    """
    builderClient helps to create or refresh the debian build recipes
    (.dsc, *.tar) based on the stx source, then it offloads the build
    task to the container 'pkgbuilder' with customer's build options
    The build log will be displayed on console until getting the result
    'Status: success': build ok
    'Status: fail': build fail
    'Status: give-back': try again later
    """
    def __init__(self, distro=STX_DEFAULT_DISTRO):
        self.attrs = {
            'mode': 'private',
            'distro': distro,
            'avoid': True,
            'parallel': False,
            'exit_on_fail': False,
            'run_tests': False,
            'build_depend': False,
            'upload_source': False
        }
        self.kits = {
            'dsc_cache': {},
            'repo_mgr': None,
            'dsc_maker': {},
        }
        self.lists = {
            'uploaded': []
        }
        self.build_types = []
        self.pkgs_digests = {}
        if not self.kits['repo_mgr']:
            rlogger = logging.getLogger('repo_manager')
            utils.set_logger(rlogger)
            self.kits['repo_mgr'] = repo_manage.RepoMgr('aptly', REPOMGR_URL,
                                                        '/tmp', rlogger)
            logger.debug("Successful created repo manager")

    @property
    def build_avoid(self):
        return self.attrs['avoid']

    @build_avoid.setter
    def build_avoid(self, avoid):
        self.attrs['avoid'] = avoid

    def start(self, build_types=ALL_BUILD_TYPES):
        build_types_to_init = ALL_BUILD_TYPES
        if build_types is not None:
            build_types_to_init = build_types
        self.build_types = build_types_to_init

        for build_type in build_types_to_init:
            self.lists['success_' + build_type] = []
            self.lists['fail_' + build_type] = []
            self.lists['build-needed_' + build_type] = []
            self.lists['success_depends_' + build_type] = []
            self.lists['fail_depends_' + build_type] = []

            if not build_type in self.kits['dsc_cache']:
                pkl_file = os.path.join(BUILD_ROOT, build_type, 'dsc.pkl')
                self.kits['dsc_cache'][build_type] = dsccache.DscCache(logger, pkl_file)
                if not self.kits['dsc_cache'][build_type]:
                    logger.warning(' '.join(['Failed to create dsc cache',
                                   pkl_file]))

        if not self.kits['repo_mgr']:
            logger.critical("Failed to create repo manager")
            return False
        self.kits['repo_mgr'].upload_pkg(REPO_BUILD, None)
        self.kits['repo_mgr'].upload_pkg(REPO_SOURCE, None)

        recipes_dir = os.path.join(BUILD_ROOT, 'recipes')
        os.makedirs(recipes_dir, exist_ok=True)

        for build_type in build_types_to_init:
            build_dir = os.path.join(BUILD_ROOT, build_type)
            os.makedirs(build_dir, exist_ok=True)

            if not build_type in self.kits['dsc_maker']:
                try:
                    if build_type == 'rt':
                        self.kits['dsc_maker'][build_type] = debrepack.Parser(build_dir, recipes_dir,
                                                                              'debug', None, 'rt')
                    else:
                        self.kits['dsc_maker'][build_type] = debrepack.Parser(build_dir, recipes_dir, 'debug')
                except Exception as e:
                    logger.error(str(e))
                    logger.error("Failed to create dsc maker")
                    return False
                else:
                    logger.info("Successfully created dsc maker")

        # load the persistent chroot on shared volume
        logger.info("Loading chroot")
        req_chroots_action('loadchroot', None)
        logger.info("Successfully loaded chroot")
        return True

    def stop(self):
        return self.show_build_stats()

    def clean(self, build_types=ALL_BUILD_TYPES):
        """
        Clean the build env includes cleaning all these build artifacts under
        <path to>/std or <path to>/rt and empty the local build repo
        """

        if build_types is None:
            build_types=ALL_BUILD_TYPES

        # clean build artifacts
        for build_type in build_types:
            build_dir = os.path.join(BUILD_ROOT, build_type)
            if os.path.exists(build_dir):
                logger.debug(' '.join(['Cleaning the build directroy', build_dir]))
                try:
                    shutil.rmtree(build_dir)
                except Exception as e:
                    logger.error(str(e))
                    logger.error("Failed to clean of the build directory")
                else:
                    logger.info("Finished cleaning of the build directory")

        # clean build repo
        if self.kits['repo_mgr']:
            if not self.kits['repo_mgr'].remove_repo(REPO_BUILD):
                logger.debug(' '.join(['Failed to clean', REPO_BUILD]))
            else:
                logger.debug(' '.join(['Successfully cleaned', REPO_BUILD]))

    def add_chroot(self, mirror):
        extra_req = {}

        if mirror:
            # Extra required data can be extended here, for example:
            # req_param['mirror'] = "http://ftp.de.debian.org/debian"
            # when 'addchroot'
            extra_req['mirror'] = mirror

        ret = req_chroots_action('addchroot', extra_req)
        if 'success' in ret:
            logger.debug('Chroot exists, ready to build')
            return 'success'

        if 'creating' in ret:
            key_string = "Successfully set up bullseye chroot"
            state = show_task_log(os.path.join(PKGBUILDER_ROOT, USER, PROJECT,
                                               'chroot.log'),
                                  10, key_string, None)
            if 'success' in state:
                req_chroots_action('savechroot', None)
                ret = 'success'
            else:
                logger.error('Failed to add chroot, please consult the log')
                ret = 'fail'
            self.req_kill_task('chroot')

        return ret

    def publish_repo(self, repo_name):
        try:
            logger.info("Try to publish the repository %s", repo_name)
            self.kits['repo_mgr'].deploy_repo(repo_name)
        except Exception as e:
            logger.error(str(e))
            logger.error("Failed to publish the repository %s", repo_name)
            return False
        else:
            logger.info("Successfully published the repository %s", repo_name)
        return True

    def upload_with_deb(self, package, debs_dir, build_type):
        """
        upload the local build debian binaries to repo manager
        Params:
            package: target package name
            debs_dir: the directory to debian binaries
        """
        logger.debug(' '.join(['Remove all old version of debs for', package]))
        if build_type == 'rt':
            debs_clue = os.path.join(os.environ.get('MY_BUILD_PKG_DIR'),
                                     'debs_entry_rt.pkl')
        else:
            debs_clue = os.path.join(os.environ.get('MY_BUILD_PKG_DIR'),
                                     'debs_entry.pkl')
        subdebs = debsentry.get_subdebs(debs_clue, package, logger)
        if subdebs:
            for deb in subdebs:
                pkg_item = deb.split('_')
                msg = ''.join(['package ', pkg_item[0], '(', pkg_item[1], ')'])

                logger.info(' '.join(['Searching for binary', msg, 'in repository', REPO_BUILD]))
                if self.kits['repo_mgr'].search_pkg(REPO_BUILD, pkg_item[0], None, True):
                    logger.info('Found binary %s in repository %s', msg, REPO_BUILD)
                    if self.kits['repo_mgr'].delete_pkg(REPO_BUILD, pkg_item[0], 'binary', None, deploy=False):
                        logger.info('Successfully deleted binary %s from repository %s',
                                    msg, REPO_BUILD)
                    else:
                        logger.info('Failed to delete binary %s from repository %s', msg,
                                    REPO_BUILD)
            self.publish_repo(REPO_BUILD)

        sdebs = []
        if not os.path.exists(debs_dir):
            logger.error(' '.join(['Noneexistent directory', debs_dir]))
            return False
        for root, dirs, files in os.walk(debs_dir):
            if dirs:
                pass
            for r in files:
                if r.endswith('.deb'):
                    deb_file = os.path.join(root, r)
                    if self.kits['repo_mgr'].upload_pkg(REPO_BUILD, deb_file, deploy=False):
                        logger.info("Successfully uploaded %s to %s", deb_file, REPO_BUILD)
                        pkg_item = r.split('_')
                        if pkg_item and len(pkg_item) > 1:
                            sdebs.append('_'.join([pkg_item[0], pkg_item[1]]))
                    else:
                        logger.error("Failed to upload %s to %s", deb_file, REPO_BUILD)
                        return False

        if self.publish_repo(REPO_BUILD):
            debsentry.set_subdebs(debs_clue, package, sdebs, logger)
            logger.debug("%s_%s is saved into debs_entry", pkg_item[0], pkg_item[1])
            return True

        return False

    def upload_with_dsc(self, pkg_name, dsc, repo_name):
        if not os.path.exists(dsc):
            logger.error(' '.join(['Dsc file', dsc, 'does not exist']))
            return False

        dsc_pkg = os.path.basename(dsc).split('_')[0]
        if pkg_name != dsc_pkg:
            logger.warning(''.join(['Package name passed in is ', pkg_name,
                                    ', from dsc is ', dsc_pkg, ' ,did not match.']))
        logger.info(' '.join(['Existing source for', dsc_pkg,
                              'will be deleted from repository', repo_name, 'before new source is uploaded']))
        logger.info("Searching for %s in repository %s", dsc_pkg, repo_name)
        if self.kits['repo_mgr'].search_pkg(repo_name, dsc_pkg, None, False):
            logger.info("Found %s in repository %s, attempting to delete", dsc_pkg, repo_name)
            if not self.kits['repo_mgr'].delete_pkg(repo_name, dsc_pkg, 'source'):
                logger.error("Failed to delete source %s from repository %s", dsc_pkg, repo_name)
                return False
            logger.info("Successfully deleted source %s from repository %s", dsc_pkg, repo_name)
        else:
            logger.info("can't find %s in repository %s", dsc_pkg, repo_name)

        logger.info(' '.join(['Start to upload source', dsc, 'to repository', repo_name]))
        if not self.kits['repo_mgr'].upload_pkg(repo_name, dsc):
            logger.error("Failed to upload source %s to repository %s", dsc, repo_name)
            return False
        logger.info("Successfully uploaded source %s to repository %s", dsc, repo_name)
        return True

    def req_add_task(self, pkg_dir, dsc_path, build_type=STX_DEFAULT_BUILD_TYPE):
        status = 'fail'
        dsc = os.path.basename(dsc_path)

        pkg_name = discovery.package_dir_to_package_name(pkg_dir, self.attrs['distro'])

        req_params = {}
        req_params['mode'] = self.attrs['mode']
        req_params['type'] = build_type
        req_params['project'] = PROJECT
        req_params['user'] = USER
        req_params['name'] = pkg_name
        req_params['dsc'] = dsc
        req_params['jobs'] = get_package_jobs(pkg_dir, self.attrs['distro'])
        req_params['run_tests'] = self.attrs['run_tests']


        try:
            resp = requests.get(BUILDER_URL + 'addtask', data=req_params)
            resp.raise_for_status()
        except requests.RequestException as e:
            print(e)
        else:
            logger.debug(resp.text)
            if 'success' in resp.text:
                log = os.path.join(BUILD_ROOT, build_type, pkg_name,
                                   dsc.replace('.dsc', '_amd64.build'))
                ret = show_task_log(log, 3, 'Status: successful',
                                    'Finished at')
                if 'success' in ret:
                    self.upload_with_deb(pkg_name, os.path.join(BUILD_ROOT,
                                         build_type, pkg_name), build_type)
                    self.req_kill_task('sbuild')
                    status = 'success'
        return status

    def req_kill_task(self, owner):
        req_params = {}
        req_params['owner'] = owner
        req_params['user'] = USER
        req_params['mode'] = self.attrs['mode']

        try:
            resp = requests.get(BUILDER_URL + 'killtask', data=req_params)
            resp.raise_for_status()
        except requests.RequestException as e:
            print(e)
        else:
            logger.debug(resp.text)

    def req_stop_task(self):
        req_params = {}
        req_params['user'] = USER
        req_params['mode'] = self.attrs['mode']

        try:
            resp = requests.get(BUILDER_URL + 'stoptask', data=req_params)
            resp.raise_for_status()
        except requests.RequestException as e:
            print(e)
        else:
            logger.debug(resp.text)

    def create_dsc(self, pkg_name, pkg_dir, build_type=STX_DEFAULT_BUILD_TYPE):
        """
        Call dsc maker(debrepack) to generate the new dsc for package
        Params:
            pkg_name: package name
            pkg_dir: path to the directory containing the package's debian folder
            build_type: build type ... probably 'std' or 'rt'
        Return: result list like:
            ['dhcp-2.10.1.tis.dsc' 'dhcp-2.10.tar.xz' 'dhcp-2.10.tar.xz.orig']
        """
        dsc_file = None
        skip_create_dsc = False
        # Check whether there are changes on package's debian folder
        new_checksum = self.kits['dsc_maker'][build_type].checksum(pkg_dir)
        self.pkgs_digests[pkg_dir] = new_checksum
        if self.kits['dsc_cache'][build_type]:
            dsc_file, old_checksum = self.kits['dsc_cache'][build_type].get_package(pkg_dir)
            if dsc_file and old_checksum:
                if old_checksum and old_checksum == new_checksum:
                    logger.info("No update on package meta of %s", pkg_name)
                    if os.path.exists(dsc_file):
                        logger.info("Skip creating dsc for %s again", pkg_name)
                        skip_create_dsc = True
                        return skip_create_dsc, dsc_file
                    else:
                        logger.info("Found %s in dsc_cache, but does not exist, need to create", pkg_name)

        logger.debug("Be ready to create dsc for %s", pkg_dir)
        pkg_build_dir = os.path.join(BUILD_ROOT, build_type, pkg_name)
        if os.path.exists(pkg_build_dir):
            try:
                shutil.rmtree(pkg_build_dir)
            except Exception as e:
                logger.error(str(e))
            else:
                logger.debug("Successfully clean the old %s", pkg_build_dir)
                os.makedirs(pkg_build_dir)

        try:
            src_mirror_dir = os.path.join(os.environ.get('STX_MIRROR'), 'sources')
            dsc_recipes = self.kits['dsc_maker'][build_type].package(pkg_dir, src_mirror_dir)
        except Exception as e:
            logger.error(str(e))
            return skip_create_dsc, None
        else:
            if not dsc_recipes:
                logger.error("Failed to create dsc for %s", pkg_name)
                return skip_create_dsc, None
            logger.debug("Successfully created dsc for %s", pkg_name)
            pkg_checksum = self.pkgs_digests[pkg_dir]
            dsc_path = os.path.join(pkg_build_dir, dsc_recipes[0])
            self.kits['dsc_cache'][build_type].set_package(pkg_dir, dsc_path + ':' + pkg_checksum)
            return skip_create_dsc, os.path.join(pkg_build_dir, dsc_recipes[0])

    def get_stamp(self, pkg_dir, dsc_path, build_type, state):
        dsc_file, checksum = self.kits['dsc_cache'][build_type].get_package(pkg_dir)
        if not dsc_file or not checksum:
            return False

        if dsc_file != dsc_path:
            logger.error("Mismatched dsc path for %s", pkg_dir)
            return False

        stamp_dir = os.path.join(os.environ.get('MY_WORKSPACE'), build_type, 'stamp')
        dsc_stamp = '.'.join([os.path.basename(dsc_file), checksum, state])
        dsc_stamp_file = os.path.join(stamp_dir, dsc_stamp)
        if os.path.exists(dsc_stamp_file):
            return True
        return False

    def set_stamp(self, pkg_dir, dsc_path, build_type, state):
        dsc_file, checksum = self.kits['dsc_cache'][build_type].get_package(pkg_dir)
        if not dsc_file or not checksum:
            return False

        if dsc_file != dsc_path:
            logger.error("Mismatched dsc path for %s", pkg_dir)
            return False
        try:
            stamp_dir = os.path.join(os.environ.get('MY_WORKSPACE'), build_type, 'stamp')
            os.makedirs(stamp_dir, exist_ok=True)
            dsc_stamp = '.'.join([os.path.basename(dsc_file), checksum, state])
            os.mknod(os.path.join(stamp_dir, dsc_stamp))
        except Exception as e:
            logger.error(str(e))
            logger.error("Failed to create stamp(%s) for %s", state, pkg_dir)
            return False
        else:
            logger.info("Successfully create stamp(%s) for %s", state, pkg_dir)
            return False

    def del_stamp(self, pkg_dir, dsc_path, build_type, state):
        dsc_file, checksum = self.kits['dsc_cache'][build_type].get_package(pkg_dir)
        if not dsc_file or not checksum:
            return False

        if dsc_file != dsc_path:
            logger.warning("Mismatched dsc path for %s", pkg_dir)
            return False
        try:
            stamp_dir = os.path.join(os.environ.get('MY_WORKSPACE'), build_type, 'stamp')
            dsc_stamp = '.'.join([os.path.basename(dsc_file), checksum, state])
            dsc_stamp_file = os.path.join(stamp_dir, dsc_stamp)
            if not os.path.exists(dsc_stamp_file):
                return True
            os.remove(dsc_stamp_file)
        except Exception as e:
            logger.error(str(e))
            logger.error("Failed to remove stamp(%s) for %s", state, pkg_dir)
            return False
        else:
            logger.info("Successfully removed stamp(%s) for %s", state, pkg_dir)
            return True

    def clean_build_output(self, dsc_path):
        try:
            build_dir = os.path.abspath(dsc_path)
            if build_dir:
                os.system("rm -f %s" % os.path.join(build_dir, '*.deb'))
        except Exception as e:
            logger.error(str(e))
            logger.error("Failed to remove the old deb packages")
        else:
            logger.debug("Successfully removed the old deb packages")

    def run_build_loop(self, layer_pkgdir_dscs, target_pkgdir_dscs, layer, build_type=STX_DEFAULT_BUILD_TYPE):
        '''
        Prerequisite to run this function is that the phase I build(dsc creating) done
        layer_pkgdir_dscs: Dict of the full layer packages
        target_pkgdir_dscs: Dict of the target packages
        layer: The layer currently build
        build_type: type of build
        '''
        build_dir = os.path.join(BUILD_ROOT, build_type)
        dsc_list_file = os.path.join(build_dir, layer + '_dscs.lst')
        dscs_list = get_dsc_list_from_dict(target_pkgdir_dscs)
        logger.debug('There are %d packages to be built in this round', len(dscs_list))

        ds_logger = logging.getLogger('dsc_depend')
        if not ds_logger.handlers:
            utils.set_logger(ds_logger)
        logger.debug("All dscs of layer %s passed to dsc_depends in file %s", layer, dsc_list_file)
        logger.debug("Target dscs(%d) passed to dsc_depends: %s", len(dscs_list), str(dscs_list))
        deps_resolver = dsc_depend.Dsc_build_order(dsc_list_file, dscs_list, ds_logger)
        build_counter = {}

        # build all the target packages
        while dscs_list:
            pkgs_can_build = deps_resolver.get_build_able_pkg(1)
            if not pkgs_can_build:
                logger.warning("Depends resolver returns none")
                return
            # build all the buildable packages that dsc_depend returns
            for dsc_path in pkgs_can_build:
                logger.info("Depends resolver tells to build %s", os.path.basename(dsc_path))
                pkg_dir = get_pkg_dir_from_dsc(layer_pkgdir_dscs, dsc_path)
                pkg_name = discovery.package_dir_to_package_name(pkg_dir, distro=self.attrs['distro'])

                # For layer build, the depended packages may was built before in the higher priority layer
                if pkg_dir in self.lists['success_' + build_type]:
                    logger.warning("Package %s has been built in this round, skip", pkg_name)
                    deps_resolver.pkg_accomplish(dsc_path)
                    dscs_list.remove(dsc_path)
                    continue

                # For the depended packages, skip checking the 'avoid' option
                if not pkg_dir in target_pkgdir_dscs.keys():
                    if self.get_stamp(pkg_dir, dsc_path, build_type, 'build_done'):
                        logger.info("Stamp[build_done] found for the depended package %s, skip building", pkg_name)
                        deps_resolver.pkg_accomplish(dsc_path)
                        continue
                    # If the option 'build_depend' disabled, just exit
                    if not self.attrs['build_depend']:
                        logger.error("The depended package %s has not been built", pkg_name)
                        return
                # For the target packages
                else:
                    if self.attrs['avoid']:
                        if self.get_stamp(pkg_dir, dsc_path, build_type, 'build_done'):
                            logger.info("Stamp build_done found, package %s has been built, skip", pkg_name)
                            self.lists['success_' + build_type].append(pkg_dir)
                            deps_resolver.pkg_accomplish(dsc_path)
                            dscs_list.remove(dsc_path)
                            continue

                self.del_stamp(pkg_dir, dsc_path, build_type, 'build_done')
                self.clean_build_output(dsc_path)
                status = self.req_add_task(pkg_dir, dsc_path, build_type=build_type)
                if pkg_dir in build_counter.keys():
                    build_counter[pkg_dir] += 1
                else:
                    build_counter[pkg_dir] = 1
                logger.debug("Attempting to build package %s for the %d time", pkg_dir, build_counter[pkg_dir])

                if 'success' in status:
                    logger.info('Successfully built %s', pkg_name)
                    self.set_stamp(pkg_dir, dsc_path, build_type, state='build_done')
                    deps_resolver.pkg_accomplish(dsc_path)
                    if pkg_dir in target_pkgdir_dscs.keys():
                        dscs_list.remove(dsc_path)
                        logger.info('Removed dsc %s from list after successfully build', dsc_path)
                        self.lists['success_' + build_type].append(pkg_dir)
                        logger.info('Added %s to success list success_%s', pkg_dir, build_type)
                    else:
                        self.lists['success_depends_' + build_type].append(pkg_dir)
                        logger.info('Added %s to list success_depends_%s', pkg_dir, build_type)
                else:
                    if build_counter[pkg_dir] >= MAX_PKG_BUILD_COUNT:
                        deps_resolver.pkg_accomplish(dsc_path)
                        logger.warning('Notify depends resolver after %d attempts for %s', MAX_PKG_BUILD_COUNT, pkg_dir)
                        if pkg_dir in target_pkgdir_dscs.keys():
                            self.lists['fail_' + build_type].append(pkg_dir)
                            logger.error('Added %s to fail list fail_%s', pkg_dir, build_type)
                            dscs_list.remove(dsc_path)
                        else:
                            self.lists['fail_depends_' + build_type].append(pkg_dir)
                            logger.info('Added %s to list fail_depends_%s', pkg_dir, build_type)
                        logger.error("Failed to build package %s after %d attempts, giving up", pkg_dir, build_counter[pkg_dir])
                        logger.info("For the detailed reasons, please check the logs:")
                        logger.info("\'cat ${MY_WORKSPACE}/<std or rt>/<failed package>/*.build\'")
                    else:
                        deps_resolver.pkg_fail(dsc_path)
                    self.req_stop_task()
                    if self.attrs['exit_on_fail']:
                        return
        logger.info("Build done, please check the statistics")

    def build_all(self, layers=ALL_LAYERS, build_types=None, packages=None):
        if layers:
            for layer in layers:
                if layer not in ALL_LAYERS:
                    logger.error(' '.join([layer, 'is not a valid layer']))
                    return
        else:
            layers = ALL_LAYERS

        if build_types:
            for build_type in build_types:
                if build_type not in ALL_BUILD_TYPES:
                    logger.error(' '.join([build_type, 'is not a valid build_type']))
                    return

        if layers:
            total_layers = len(layers)
            logger.debug(' '.join(['Building ', str(total_layers), ' layers:',
                                   ','.join(layers)]))
            self.build_layers(layers=layers, build_types=build_types, packages=packages)
        else:
            logger.error('No layeres specified for the build.')

    def save_failed_pkgs(self, pkgs_exist, pkgs_target, build_type):
        if not pkgs_exist:
            return
        pkgs_name_fail = list(set(pkgs_target) - set(pkgs_exist))
        if not pkgs_name_fail:
            return

        for pkg in pkgs_name_fail:
            for pkgdir, pkgname in pkgs_exist.items():
                if pkgname == pkg:
                    if build_type:
                        self.lists['fail_' + build_type].append(pkgdir)
                    else:
                        self.lists['fail_std'].append(pkgdir)
    
    def build_layer_and_build_type(self, layer=None, build_type=None, packages=None):
        pkgs_exist = {}

        if not layer:
            logger.error('Failed to specify layer')
            return

        if not build_type:
            logger.error('Failed to specify build_type')
            return

        pkg_dirs = discovery.package_dir_list(distro=self.attrs['distro'], layer=layer, build_type=build_type)
        layer_pkg_dirs = pkg_dirs
        word = "all"
        if packages:
            word = "selected"
            pkg_dirs, pkgs_exist = discovery.filter_package_dirs_by_package_names(pkg_dirs, packages, distro=self.attrs['distro'])
            self.save_failed_pkgs(pkgs_exist, packages, build_type)
            layer_pkg_dirs = pkg_dirs

        if not pkg_dirs:
            logger.debug(' '.join(['Found no buildable packages matching selection criteria in',
                              'build_type', build_type,
                              'of layer', layer]))
            return

        logger.info(' '.join(['Start to build', word, 'packages in',
                              'build_type', build_type,
                              'of layer', layer]))

        packages = discovery.package_dirs_to_package_names(pkg_dirs)
        logger.debug(' '.join(['Building packages:',
                               ','.join(packages)]))
        self.build_packages(layer_pkg_dirs, pkg_dirs, layer, build_type=build_type)

        logger.info(' '.join(['Finished building packages in',
                              'build_type', build_type,
                              'of layer', layer]))


    def build_layer_and_build_types(self, layer=None, build_types=STX_DEFAULT_BUILD_TYPE_LIST, packages=None):
        if not layer:
            logger.error('Failed to specify layer')
            return

        if not build_types:
            logger.error('Failed to specify build_types')
            return

        # remove duplication
        build_types = list(set(build_types))
        '''
        The signed packages like kernel-std-signed and kernel-rt-signed need
        some interactive operations before building them, so here excluded the
        build type 'sign' from the default build types
        '''
        if not packages and 'sign' in build_types:
            del build_types['sign']

        valid_build_type = discovery.get_layer_build_types(layer, distro=self.attrs['distro'])

        # sort the build_type list so we build in the proper order
        build_types = discovery.sort_build_type_list(build_types, layer, distro=self.attrs['distro'])

        for build_type in build_types:
            if build_type not in valid_build_type:
                logger.info(' '.join(['Skipping build_type', build_type, 'which is not a valid for layer', layer]))
                continue
            self.build_layer_and_build_type(layer=layer, build_type=build_type, packages=packages)

        return

    def build_layer(self, layer=None, build_types=STX_DEFAULT_BUILD_TYPE_LIST, packages=None):
        if not layer:
            logger.error('Failed to specify layer')
            return

        if layer not in ALL_LAYERS:
            logger.error(' '.join([layer, 'is not a valid layer']))
            return

        logger.info(' '.join(['Start to build all packages in layer',
                             layer]))
        self.build_layer_and_build_types(layer=layer, build_types=build_types, packages=packages)
        logger.info(' '.join(['Finished building packages in layer',
                              layer]))
        return


    def build_layers(self, layers=None, build_types=None, packages=None):
        if not layers:
            logger.error('Failed to specify layers')
            return

        # remove duplication
        layers = list(set(layers))

        for layer in layers:
            if layer not in ALL_LAYERS:
                logger.error(' '.join([layer, 'is not a valid layer']))
                return

        # sort the layer list so we build in the proper order
        layers = discovery.sort_layer_list(layers, distro=self.attrs['distro'])

        for layer in layers:
            if build_types is None:
                build_types = discovery.get_layer_build_types(layer=layer, distro=self.attrs['distro'])
            self.build_layer(layer=layer, build_types=build_types, packages=packages)

        return

    def build_packages(self, layer_pkg_dirs, pkg_dirs, layer, build_type=STX_DEFAULT_BUILD_TYPE):
        # remove duplication
        pkg_dirs = list(set(pkg_dirs))
        logger.debug(' '.join(['build_packages: Building: ', str(pkg_dirs)]))

        fdsc_file = None
        layer_pkgdir_dscs = {}
        logger.debug('Length of build-needed_%s:%d before extending', build_type, len(self.lists['build-needed_' + build_type]))
        self.lists['build-needed_' + build_type].extend(pkg_dirs)
        logger.debug('Length of build-needed_%s:%d after extending', build_type, len(self.lists['build-needed_' + build_type]))

        build_dir = os.path.join(BUILD_ROOT, build_type)
        os.makedirs(build_dir, exist_ok=True)

        dscs_list_file = os.path.join(build_dir, layer + '_dscs.lst')
        logger.debug(' '.join(['Prepare', dscs_list_file, 'to deps_resolver']))
        fdsc_file = open(dscs_list_file, 'w+')
        fdsc_file.seek(0)
        fdsc_file.truncate()

        # Now check and create the debian meta one by one
        for pkg_dir in layer_pkg_dirs:
            dsc_file = ""
            pkg_name = discovery.package_dir_to_package_name(pkg_dir, distro=self.attrs['distro'])
            skip_dsc, dsc_file = self.create_dsc(pkg_name, pkg_dir, build_type=build_type)
            if dsc_file:
                logger.debug("dsc_file = %s" % dsc_file)
                layer_pkgdir_dscs[pkg_dir.strip()] = dsc_file
                fdsc_file.write(dsc_file + '\n')
                if self.attrs['upload_source'] and not skip_dsc and self.kits['repo_mgr']:
                    self.upload_with_dsc(pkg_name, dsc_file, REPO_SOURCE)
            elif dsc_file is None:
                # Exit if fails to create dsc file
                if fdsc_file:
                    fdsc_file.close()
                logger.error("Failed to create needed dsc file, exit")
                return
            else:
                # Empty set indicates the package is unchanged
                continue

        if fdsc_file:
            fdsc_file.close()

        # Start to build
        target_pkgdir_dscs = {}
        for pkg in pkg_dirs:
            if pkg in layer_pkgdir_dscs.keys():
                target_pkgdir_dscs[pkg] = layer_pkgdir_dscs[pkg]

        if target_pkgdir_dscs:
            self.run_build_loop(layer_pkgdir_dscs, target_pkgdir_dscs, layer, build_type=build_type)
        else:
            logger.info("No debian dsc files found")

    def show_build_stats(self):
        """
        Since all packages are put into self.lists['build-needed']
        at the begining of building, we know how many
        packages want to build
        """
        ret_val = 0
        for build_type in self.build_types:
            logger.info("Total %s packages needing to be built: %d", build_type, len(self.lists['build-needed_' + build_type]))
            success_list = list(set(self.lists['success_' + build_type]))
            success_number = len(success_list)
            if success_number > 0:
                logger.info("Successfully built: %d", success_number)
                for pkg_dir in sorted(success_list):
                    pkg_name = discovery.package_dir_to_package_name(pkg_dir, self.attrs['distro'])
                    logger.info(pkg_name)

            success_depends_list = list(set(self.lists['success_depends_' + build_type]))
            success_depends_number = len(success_depends_list)
            if success_depends_number > 0:
                logger.info("Successfully built depended packages: %d", success_depends_number)
                for pkg_dir in sorted(success_depends_list):
                    pkg_name = discovery.package_dir_to_package_name(pkg_dir, self.attrs['distro'])
                    logger.info(pkg_name)

            failed_pkg_dirs = list(set(self.lists['build-needed_' + build_type]) - set(self.lists['success_' + build_type]))
            failed_number = len(failed_pkg_dirs)
            if failed_number > 0:
                ret_val = 1
                logger.error("Failed to build: %d", failed_number)
                for pkg_dir in sorted(failed_pkg_dirs):
                    pkg_name = discovery.package_dir_to_package_name(pkg_dir, self.attrs['distro'])
                    logger.error(pkg_name)
                # self.lists['fail'] is the subset of failed_pkg_dirs
                # particularly refer to those failed packages reported by pkgbuilder
                if len(self.lists['fail_' + build_type]) > 0:
                    logger.info("List of failed packages:")
                    for pkg_dir in sorted(list(set(self.lists['fail_' + build_type]))):
                        pkg_name = discovery.package_dir_to_package_name(pkg_dir, self.attrs['distro'])
                        logger.error(pkg_name)
                logger.info("For the failure reason, you can check with:")
                logger.info("\'cat /localdisk/builder.log | grep ERROR\' or")
                logger.info("\'cat ${MY_WORKSPACE}/<std or rt>/<Failed package>/*.build\'")
        return ret_val


def bc_signal_handler(signum, frame):
    ret_val = 0
    if not build_controller:
        sys.exit(1)

    if frame:
        logger.debug(' '.join(['Signal', str(signum), 'got']))
    logger.debug('Request to stop building tasks')
    build_controller.req_stop_task()
    ret_val = build_controller.show_build_stats()
    logger.debug('Exit for user interruption')
    sys.exit(ret_val)


def bc_reg_signal_handler():
    signal.signal(signal.SIGINT, bc_signal_handler)
    signal.signal(signal.SIGHUP, bc_signal_handler)
    signal.signal(signal.SIGTERM, bc_signal_handler)


if __name__ == "__main__":
    distro = STX_DEFAULT_DISTRO
    layers = None
    build_types = None
    packages = None

    parser = argparse.ArgumentParser(description="build-pkgs helper")
    parser.add_argument('-c', '--clean', help="Start a fresh build",
                        action='store_true')
    parser.add_argument('-e', '--exit_on_fail', help="Exit for any fail",
                        action='store_true')
    parser.add_argument('-t', '--test', help="Run package tests during build",
                        action='store_true')
    parser.add_argument('-d', '--distro', type=str, nargs=1,
                        help="name of the distro to build\n   %s" % ALL_DISTROS,
                        default=STX_DEFAULT_DISTRO, required=False)
    parser.add_argument('-b', '--build-types', type=str,
                        help="comma separated list of all build-types to build\n   %s" % ALL_BUILD_TYPES,
                        default=None, required=False)
    parser.add_argument('-l', '--layers', type=str, 
                        help="comma separated list of all layers to build\n   %s" % ALL_LAYERS,
                        default=None, required=False)
    # set mutually options pair for package build and layer build
    build_group = parser.add_mutually_exclusive_group()
    build_group.add_argument('-a', '--all', help="Builds all packages",
                             action='store_true')
    build_group.add_argument('-p', '--packages', help="Packages with comma",
                             type=str)
    args = parser.parse_args()

    if args.distro:
        if args.distro not in ALL_DISTROS:
            logger.error(' '.join(['Distro', args.distro, 'not in', ','.join(ALL_DISTROS)]))
            logger.error("Please consult: build-pkgs --help")
            sys.exit(1)
        distro = args.distro
        ALL_LAYERS = discovery.get_all_layers(distro=distro)
        ALL_BUILD_TYPES = discovery.get_all_build_types(distro=distro)

    if args.build_types:
        build_types = args.build_types.strip().split(',')
        for build_type in build_types:
            if build_type not in ALL_BUILD_TYPES:
                logger.error(' '.join(['Build_type', build_type, 'not in', ','.join(ALL_BUILD_TYPES)]))
                logger.error("Please consult: build-pkgs --help")
                sys.exit(1)

    if args.layers:
        layers = args.layers.strip().split(',')
        for layer in layers:
            if layer not in ALL_LAYERS:
                logger.error(' '.join(['Layer', layer, 'not in', ','.join(ALL_LAYERS)]))
                logger.error("Please consult: build-pkgs --help")
                sys.exit(1)

    if args.packages:
        packages = args.packages.strip().split(',')
    else:
        if args.all:
            packages = None

    build_controller = BuildController(distro=distro)
    if args.clean:
        build_controller.build_avoid = False
        if args.all:
            build_controller.clean(build_types=build_types)
    if args.exit_on_fail:
        build_controller.attrs['exit_on_fail'] = True
    if args.test:
        build_controller.attrs['run_tests'] = True

    if not build_controller.start(build_types=build_types):
        logger.critical("Fail to initialize build controller, exit ......")
        sys.exit(1)

    bc_reg_signal_handler()

    # mirror can be set to add_chroot as the main package repo
    # e.g http://ftp.de.debian.org/debian
    if build_controller.add_chroot(os.environ.get('DEBIAN_SNAPSHOT')) != 'success':
        pkgbuilder_log = '/localdisk/pkgbuilder/pkgbuilder.log'
        logger.error(' '.join(['Chroot is not ready, please check',
                              pkgbuilder_log]))
        sys.exit(1)

    build_controller.build_all(layers=layers, build_types=build_types, packages=packages)
    ret_value = build_controller.stop()

    logger.info("build-pkgs done")
    sys.exit(ret_value)
